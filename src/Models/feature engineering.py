import os
import pandas as pd

def generate_features(dataframe):
    """
    Perform comprehensive feature engineering on the dataframe.
    """
    # Ensure the dataframe is sorted by date for accurate calculations
    dataframe = dataframe.sort_values(by='date_id')
    
    # Sales-related lag features
    dataframe['net_sales_lag_1'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(1)
    dataframe['net_sales_lag_2'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(2)
    dataframe['net_sales_lag_3'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(3)
    dataframe['net_sales_lag_4'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(4)
    dataframe['net_sales_lag_5'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(5)
    dataframe['net_sales_lag_6'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].shift(6)
    
    # Rolling window statistics
    dataframe['rolling_mean_3_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=3).mean().reset_index(level=[0, 1], drop=True)
    dataframe['rolling_std_3_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=3).std().reset_index(level=[0, 1], drop=True)
    dataframe['rolling_mean_7_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=7).mean().reset_index(level=[0, 1], drop=True)
    dataframe['rolling_std_7_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=7).std().reset_index(level=[0, 1], drop=True)
    dataframe['rolling_mean_14_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=14).mean().reset_index(level=[0, 1], drop=True)
    dataframe['rolling_std_14_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].rolling(window=14).std().reset_index(level=[0, 1], drop=True)
    dataframe['ema_7_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].ewm(span=7, adjust=False).mean().reset_index(level=[0, 1], drop=True)
    dataframe['ema_30_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].ewm(span=30, adjust=False).mean().reset_index(level=[0, 1], drop=True)
    dataframe['cumulative_net_sales'] = dataframe.groupby(['item_dept', 'store'])['net_sales'].cumsum()

    # Item related features
    dataframe['mean_net_sales_by_dept'] = dataframe.groupby('item_dept')['net_sales'].transform('mean')
    dataframe['max_net_sales_by_dept'] = dataframe.groupby('item_dept')['net_sales'].transform('max')
    dataframe['min_net_sales_by_dept'] = dataframe.groupby('item_dept')['net_sales'].transform('min')
    dataframe['item_count_by_dept'] = dataframe.groupby('item_dept')['item_qty'].transform('count')

    # Extract time-based features
    dataframe['month'] = dataframe['date_id'].dt.month
    dataframe['day_of_week'] = dataframe['date_id'].dt.dayofweek
    dataframe['year'] = dataframe['date_id'].dt.year
    dataframe['week_of_year'] = dataframe['date_id'].dt.isocalendar().week
    dataframe['is_weekend'] = dataframe['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)
    
    # Outlet-based features
    dataframe['mean_sales_by_store'] = dataframe.groupby('store')['net_sales'].transform('mean')
    dataframe['max_sales_by_store'] = dataframe.groupby('store')['net_sales'].transform('max')
    dataframe['min_sales_by_store'] = dataframe.groupby('store')['net_sales'].transform('min')
    dataframe['total_sales_by_store'] = dataframe.groupby('store')['net_sales'].transform('sum')

    # Interaction features
    dataframe['interaction_lag1_lag2'] = dataframe['net_sales_lag_1'] * dataframe['net_sales_lag_2']
    dataframe['interaction_lag1_rolling3'] = dataframe['net_sales_lag_1'] * dataframe['rolling_mean_3_net_sales']
    
    # Handle NaN values generated by lag and rolling calculations
    dataframe.fillna(0, inplace=True)
    
    return dataframe

if __name__ == '__main__':
    # Define file paths
    data_dir = 'D:/Data Science/Sem 3/Machine Learning/Course work/5/data/Processed'
    
    # Load the final processed data
    processed_file_path = os.path.join(data_dir, 'final_processed_data.csv')
    final_data = pd.read_csv(processed_file_path, parse_dates=['date_id'])
    
    # Apply feature engineering
    engineered_data = generate_features(final_data)
    
    # Split the data into training and test datasets
    train_data = engineered_data[(engineered_data['date_id'] >= '2021-11-01') & (engineered_data['date_id'] <= '2022-01-31')]
    test_data = engineered_data[(engineered_data['date_id'] >= '2022-02-01') & (engineered_data['date_id'] <= '2022-02-28')]
    
    # Save the training and test datasets
    train_data.to_csv(os.path.join(data_dir, 'train_featured_data.csv'), index=False)
    test_data.to_csv(os.path.join(data_dir, 'test_featured_data.csv'), index=False)
    
    print(f"Feature engineering process is completed and datasets saved to '{data_dir}'.")